---
title: "VMS Data Quality Control Report"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(dplyr)
library(ggplot2)
library(tidyr)
library(lubridate)
library(stringr)
library(DT)
```

# VMS Data Quality Control Report

This report provides a comprehensive analysis of the fisheries VMS data quality.

## 1. Data Import and Overview

```{r data_import}
# Import the data
data <- readRDS("data/VMS2025.rds")

# Overview
cat("Total records:", nrow(data), "\n")
cat("Date range:", min(data$year), "to", max(data$year), "\n")
cat("Countries:", paste(unique(data$country), collapse = ", "), "\n")
```

## 2. Data Submissions by Country
```{r submissions_by_country, fig.width=12, fig.height=8}
# Create a more informative visualization of data submissions
import_summary <- data %>%
  mutate(importDate = as.Date(importDate),
         import_year = format(importDate, "%Y"),
         import_month = format(importDate, "%Y-%m")) %>%
  group_by(country, import_year) %>%
  summarise(records = n(), .groups = "drop") %>%
  arrange(country, import_year)

# 1. Total records by country (bar chart)
total_by_country <- import_summary %>%
  group_by(country) %>%
  summarize(total_records = sum(records)) %>%
  ggplot(aes(x = reorder(country, -total_records), y = total_records/1000000)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste0(round(total_records/1000000, 1), "M")), 
            vjust = -0.5, size = 3) +
  theme_bw() +
  labs(
    title = "Total Records by Country",
    subtitle = "In millions of records",
    x = "Country",
    y = "Records (millions)"
  )

# 2. Heatmap showing records by country and import year
yearly_heatmap <- import_summary %>%
  ggplot(aes(x = import_year, y = reorder(country, -records), fill = records)) +
  geom_tile() +
  scale_fill_viridis_c(
    trans = "log10", 
    labels = function(x) format(x, scientific = FALSE, big.mark = ","),
    name = "Records"
  ) +
  theme_bw() +
  labs(
    title = "Records by Import Year and Country",
    subtitle = "Logarithmic color scale",
    x = "Import Year",
    y = "Country"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Arrange plots in a grid
gridExtra::grid.arrange(total_by_country, yearly_heatmap, ncol = 1)

# For the original data table, group by year to make it more readable
yearly_summary <- data %>%
  mutate(importDate = as.Date(importDate),
         import_year = format(importDate, "%Y")) %>%
  group_by(country, import_year) %>%
  summarise(records = n(), .groups = "drop") %>%
  arrange(country, import_year) %>%
  pivot_wider(names_from = import_year, values_from = records, values_fill = 0)

datatable(yearly_summary)
```

## 3. Records by Year and Country

```{r records_by_year_country}
yearly_summary <- data %>%
  group_by(country, year) %>%
  summarise(records = n(), .groups = "drop")

ggplot(yearly_summary, aes(x = year, y = records, group = country, color = country)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "Number of Records by Year and Country",
       x = "Year", y = "Number of Records") +
  scale_x_continuous(breaks = seq(min(yearly_summary$year), max(yearly_summary$year), by = 1))

datatable(pivot_wider(yearly_summary, names_from = year, values_from = records))
```

## 4. Vessel Length Categories
```{r vessel_length, fig.width=12, fig.height=8}
# Create a visualization that highlights different vessel length category coding systems
vessel_length_summary <- data %>%
  group_by(country, vessel_length_category, year) %>%
  summarise(records = n(), .groups = "drop")

  unique_categories <- vessel_length_summary %>%
    select(country, vessel_length_category) %>%
    distinct() %>%
    arrange(country, vessel_length_category)
  
  category_usage <- vessel_length_summary %>%
    select(country, vessel_length_category) %>%
    distinct() %>%
    group_by(vessel_length_category) %>%
    mutate(category_count = n()) %>%
    ungroup() %>%
    mutate(present = 1) %>%
    pivot_wider(
      id_cols = country,
      names_from = vessel_length_category,
      values_from = present,
      values_fill = 0
    ) %>%
    pivot_longer(
      cols = -country,
      names_to = "vessel_length_category",
      values_to = "present"
    ) %>%
    group_by(vessel_length_category) %>%
    mutate(category_freq = sum(present)) %>%
    ungroup()
  
  coding_heatmap <- ggplot(category_usage, 
                           aes(x = reorder(vessel_length_category, -category_freq), 
                               y = country, 
                               fill = factor(present))) +
    geom_tile() +
    scale_fill_manual(
      values = c("0" = "white", "1" = "steelblue"),
      labels = c("Not used", "Used"),
      name = ""
    ) +
    theme_bw() +
    labs(
      title = "Vessel Length Categories Used by Each Country",
      subtitle = "Highlighting differences in coding systems",
      x = "Vessel Length Category",
      y = "Country"
    ) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  last_submission <- vessel_length_summary %>%
    group_by(country) %>%
    summarise(last_year = max(year)) %>%
    mutate(submission_status = ifelse(last_year < 2019, 
                                      "Not submitted since 2018", 
                                      "Recent submissions"))
  
  submission_plot <- ggplot(last_submission, 
                            aes(x = reorder(country, last_year), 
                                y = last_year, 
                                fill = submission_status)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = last_year), hjust = -0.2) +
    scale_fill_manual(
      values = c("Not submitted since 2018" = "tomato", 
                 "Recent submissions" = "steelblue")
    ) +
    coord_flip() +
    theme_bw() +
    labs(
      title = "Most Recent Data Submission Year by Country",
      subtitle = "Highlighting countries that have not submitted since 2018",
      x = "Country",
      y = "Last Submission Year",
      fill = "Submission Status"
    ) +
    scale_y_continuous(limits = c(2008, 2024))
  
  # Create a visualization focused specifically on Portugals deprecated codes
  pt_categories <- vessel_length_summary %>%
    filter(country == "PT") %>%
    group_by(vessel_length_category, year) %>%
    summarise(records = sum(records), .groups = "drop")
  
  pt_plot <- ggplot(pt_categories, 
                    aes(x = year, y = records, fill = vessel_length_category)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    labs(
      title = "Portugal's Vessel Length Categories Over Time",
      subtitle = "Showing deprecated length coding system",
      x = "Year",
      y = "Number of Records",
      fill = "Length Category"
    ) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Arrange plots in a grid to tell the complete story
  gridExtra::grid.arrange(coding_heatmap, submission_plot, pt_plot, 
                          layout_matrix = rbind(c(1,1), c(2,3)),
                          heights = c(1.5, 1))
  
  # Create a summary table of vessel length categories by country
  category_summary <- unique_categories %>%
    group_by(country) %>%
    summarise(
      categories_used = paste(sort(vessel_length_category), collapse = ", "),
      number_of_categories = n_distinct(vessel_length_category)
    ) %>%
    left_join(last_submission, by = "country") %>%
    arrange(desc(number_of_categories))
  
  datatable(category_summary)
```

## 5. Gear Codes Analysis

```{r gear_codes}
gear_summary <- data %>%
  group_by(country, year, gear_code) %>%
  summarise(records = n(), .groups = "drop") %>%
  arrange(country, year, gear_code)

ggplot(gear_summary, aes(x = gear_code, y = records, fill = factor(year))) +
  geom_col(position = "dodge") +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Number of Records by Gear Code",
       x = "Gear Code", y = "Number of Records",
       fill = "Year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

datatable(gear_summary)
```

## 6. Métier Analysis

```{r metier_analysis}
metier_summary <- data %>%
  group_by(country, year, LE_MET_level5) %>%
  summarise(records = n(), .groups = "drop") %>%
  arrange(country, year, LE_MET_level5)

ggplot(metier_summary, aes(x = LE_MET_level5, y = records, fill = factor(year))) +
  geom_col(position = "dodge") +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Number of Records by Métier Level 5",
       x = "Métier Level 5", y = "Number of Records",
       fill = "Year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

datatable(metier_summary)
```

## 7. Fishing Speed Analysis

```{r fishing_speed}
# Extract simplified metier from LE_MET_level6
data_with_simple_metier <- data %>%
  filter(!is.na(avg_fishing_speed)) %>%
  mutate(
    simplified_metier = case_when(
      str_detect(LE_MET_level6, "^PTM_SPF") ~ "PTM_SPF",
      str_detect(LE_MET_level6, "^PTM_") ~ "PTM_other",
      str_detect(LE_MET_level6, "^OTB_DEF") ~ "OTB_DEF",
      str_detect(LE_MET_level6, "^OTB_") ~ "OTB_other",
      str_detect(LE_MET_level6, "^SSC_") ~ "SSC",
      str_detect(LE_MET_level6, "^SDN_") ~ "SDN",
      str_detect(LE_MET_level6, "^OTM_") ~ "OTM",
      str_detect(LE_MET_level6, "^DRB_") ~ "DRB",
      TRUE ~ substr(LE_MET_level6, 1, 6)
    )
  )

ggplot(data_with_simple_metier, aes(x = avg_fishing_speed)) +
  geom_histogram(bins = 30) +
  facet_grid(country ~ simplified_metier, scales = "free_y") +
  theme_minimal() +
  labs(title = "Distribution of Fishing Speed by Country and Simplified Métier",
       x = "Average Fishing Speed", y = "Count") +
  theme(strip.text.y = element_text(angle = 0))

metier_speed_summary <- data_with_simple_metier %>%
  group_by(country, simplified_metier) %>%
  summarise(
    count = n(),
    min_speed = min(avg_fishing_speed, na.rm = TRUE),
    max_speed = max(avg_fishing_speed, na.rm = TRUE),
    avg_speed = mean(avg_fishing_speed, na.rm = TRUE),
    median_speed = median(avg_fishing_speed, na.rm = TRUE),
    sd_speed = sd(avg_fishing_speed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(country, simplified_metier)

datatable(metier_speed_summary)
```

## 8. Fishing Hours Analysis

```{r fishing_hours}
ggplot(data, aes(x = country, y = fishing_hours)) +
  geom_boxplot(outlier.size = 1) +
  theme_minimal() +
  labs(title = "Distribution of Fishing Hours by Country",
       x = "Country", y = "Fishing Hours") +
  coord_cartesian(ylim = c(0, quantile(data$fishing_hours, 0.95, na.rm = TRUE)))

hours_summary <- data %>%
  group_by(country) %>%
  summarise(
    count = n(),
    min_hours = min(fishing_hours, na.rm = TRUE),
    max_hours = max(fishing_hours, na.rm = TRUE),
    avg_hours = mean(fishing_hours, na.rm = TRUE),
    median_hours = median(fishing_hours, na.rm = TRUE),
    sd_hours = sd(fishing_hours, na.rm = TRUE),
    q95_hours = quantile(fishing_hours, 0.95, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(country)

datatable(hours_summary)
```

## 9. Vessel Characteristics

```{r vessel_characteristics}
vessel_data <- data %>%
  mutate(
    kw_status = case_when(
      is.na(avg_kw) ~ "NA",
      avg_kw == 0 ~ "Zero",
      avg_kw < 0 ~ "Negative",
      avg_kw > 5000 ~ "Suspicious (>5000)",
      TRUE ~ "Normal"
    ),
    oal_status = case_when(
      is.na(avg_oal) ~ "NA",
      avg_oal == 0 ~ "Zero",
      avg_oal < 0 ~ "Negative",
      avg_oal > 150 ~ "Suspicious (>150)",
      TRUE ~ "Normal"
    )
  )

ggplot(vessel_data %>% filter(kw_status == "Normal"), 
       aes(x = avg_kw/1000)) +
  geom_histogram(bins = 30) +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Distribution of Normal Vessel Power (MW) by Country",
       x = "Average MW", y = "Count")

ggplot(vessel_data %>% filter(oal_status == "Normal"), 
       aes(x = avg_oal)) +
  geom_histogram(bins = 30) +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Distribution of Normal Vessel Length (OAL) by Country",
       x = "Average OAL", y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

vessel_summary <- vessel_data %>%
  group_by(country, year) %>%
  summarise(
    records = n(),
    # KW stats
    kw_na_pct = 100 * sum(kw_status == "NA") / n(),
    kw_zero_pct = 100 * sum(kw_status == "Zero") / n(),
    kw_neg_pct = 100 * sum(kw_status == "Negative") / n(),
    kw_sus_pct = 100 * sum(kw_status == "Suspicious (>5000)") / n(),
    avg_kw = mean(avg_kw, na.rm = TRUE),
    # OAL stats
    oal_na_pct = 100 * sum(oal_status == "NA") / n(),
    oal_zero_pct = 100 * sum(oal_status == "Zero") / n(),
    oal_neg_pct = 100 * sum(oal_status == "Negative") / n(),
    oal_sus_pct = 100 * sum(oal_status == "Suspicious (>150)") / n(),
    avg_oal = mean(avg_oal, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(country, year)

datatable(vessel_summary)
```

## 10. Gear Width Analysis

```{r gear_width}
# Check for placeholder values
placeholders <- c(-999, 999999)

gear_width_summary <- data %>%
  mutate(
    placeholder_flag = avg_gearWidth %in% placeholders | is.na(avg_gearWidth),
    width_category = case_when(
      placeholder_flag ~ "Placeholder/NA",
      avg_gearWidth > 1000 ~ "Very Large (>1000m)",
      avg_gearWidth > 300 ~ "Large (300-1000m)",
      avg_gearWidth > 30 ~ "Medium (30-300m)",
      avg_gearWidth > 5 ~ "Small (5-30m)",
      avg_gearWidth > 0.3 ~ "Very Small (0.3-5m)",
      avg_gearWidth > 0 ~ "Tiny (<0.3m)",
      TRUE ~ "Zero/Negative"
    )
  ) %>%
  group_by(country, gear_code, width_category) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(country, gear_code, width_category)

ggplot(gear_width_summary, aes(x = gear_code, y = count, fill = width_category)) +
  geom_col() +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Gear Width Categories by Country and Gear Code",
       x = "Gear Code", y = "Count",
       fill = "Width Category") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

datatable(gear_width_summary)

# Special check for seine gears (SDN and SSC)
seine_gears <- data %>%
  filter(gear_code %in% c("SDN", "SSC")) %>%
  filter(!is.na(avg_gearWidth))

if (nrow(seine_gears) > 0) {
  ggplot(seine_gears, aes(x = gear_code, y = avg_gearWidth)) +
    geom_boxplot() +
    facet_wrap(~country, scales = "free_y") +
    theme_minimal() +
    labs(title = "Gear Width for Seine Gears (SDN, SSC)",
         x = "Gear Code", y = "Average Gear Width")
  
  datatable(head(seine_gears, 20))
}
```

## 11. Average Interval Analysis

```{r interval_analysis}
interval_summary <- data %>%
  filter(!is.na(AverageInterval)) %>%
  group_by(country) %>%
  summarise(
    count = n(),
    min_interval = min(AverageInterval, na.rm = TRUE),
    max_interval = max(AverageInterval, na.rm = TRUE),
    avg_interval = mean(AverageInterval, na.rm = TRUE),
    median_interval = median(AverageInterval, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(country) %>%
  mutate(
    likely_unit = case_when(
      avg_interval < 5 ~ "Likely hours",
      avg_interval >= 5 & avg_interval < 300 ~ "Likely minutes",
      avg_interval >= 300 ~ "Suspicious (very large)",
      TRUE ~ "Unknown"
    )
  )

ggplot(data %>% filter(!is.na(AverageInterval)), 
      aes(x = AverageInterval)) +
  geom_histogram(bins = 30) +
  facet_wrap(~country, scales = "free") +
  theme_minimal() +
  labs(title = "Distribution of Average Interval by Country",
       x = "Average Interval", y = "Count")

datatable(interval_summary)
```

## 12. Habitat and Depth Analysis

```{r habitat_depth}
habitat_depth_summary <- data %>%
  group_by(country, year) %>%
  summarise(
    records = n(),
    habitat_na = sum(is.na(HabitatType)),
    habitat_na_pct = 100 * habitat_na / records,
    habitat_values = n_distinct(HabitatType, na.rm = TRUE),
    depth_na = sum(is.na(DepthRange)),
    depth_na_pct = 100 * depth_na / records,
    depth_values = n_distinct(DepthRange, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(country, year)

datatable(habitat_depth_summary)

# Distribution of habitat types
habitat_dist <- data %>%
  filter(!is.na(HabitatType)) %>%
  group_by(country, year, HabitatType) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(country, year, desc(count))

ggplot(habitat_dist, aes(x = HabitatType, y = count, fill = factor(year))) +
  geom_col(position = "dodge") +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Distribution of Habitat Types by Country and Year",
       x = "Habitat Type", y = "Count",
       fill = "Year") +
  theme(axis.text.x = element_blank())

# Distribution of depth ranges
depth_dist <- data %>%
  filter(!is.na(DepthRange)) %>%
  group_by(country, year, DepthRange) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(country, year, desc(count))

ggplot(depth_dist, aes(x = DepthRange, y = count, fill = factor(year))) +
  geom_col(position = "dodge") +
  facet_wrap(~country, scales = "free_y") +
  theme_minimal() +
  labs(title = "Distribution of Depth Ranges by Country and Year",
       x = "Depth Range", y = "Count",
       fill = "Year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## 13. Swept Area Analysis

```{r swept_area}
swept_summary <- data %>%
  group_by(country, year) %>%
  summarise(
    records = n(),
    sa_na = sum(is.na(SweptArea)),
    sa_na_pct = 100 * sa_na / records,
    sa_zero = sum(SweptArea == 0, na.rm = TRUE),
    sa_zero_pct = 100 * sa_zero / (records - sa_na),
    min_sa = min(SweptArea, na.rm = TRUE),
    max_sa = max(SweptArea, na.rm = TRUE),
    avg_sa = mean(SweptArea, na.rm = TRUE),
    q95_sa = quantile(SweptArea, 0.95, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(country, year) %>%
  mutate(
    likely_unit = case_when(
      is.na(avg_sa) ~ "No data",
      avg_sa == 0 ~ "All zeros",
      avg_sa < 1 ~ "Likely sq. kilometers",
      avg_sa >= 1 & avg_sa < 10000 ~ "Likely sq. meters",
      avg_sa >= 10000 ~ "Suspicious (very large)",
      TRUE ~ "Unknown"
    )
  )

ggplot(data %>% filter(!is.na(SweptArea), SweptArea > 0), 
       aes(x = SweptArea)) +
  geom_histogram(bins = 30) +
  facet_wrap(~country, scales = "free_y") + # Only y-axis is free, x-axis is fixed
  theme_minimal() +
  labs(title = "Distribution of Swept Area by Country (non-zero values)",
       x = "Swept Area", y = "Count") +
  scale_x_log10()

ggplot(data %>% filter(!is.na(SweptArea), SweptArea > 0), 
       aes(x = country, y = SweptArea)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution of Swept Area by Country (non-zero values)",
       x = "Country", y = "Swept Area") +
  scale_y_log10() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

  datatable(swept_summary)
```

## 14. Overall Data Quality Assessment

```{r quality_assessment}
# Calculate various metrics that might indicate data quality issues
anomaly_metrics <- data %>%
  group_by(country, year) %>%
  summarise(
    records = n(),
    
    # Missing data percentages
    missing_fishing_speed = 100 * sum(is.na(avg_fishing_speed)) / n(),
    missing_gear_width = 100 * sum(is.na(avg_gearWidth)) / n(),
    missing_kw = 100 * sum(is.na(avg_kw)) / n(),
    missing_oal = 100 * sum(is.na(avg_oal)) / n(),
    missing_habitat = 100 * sum(is.na(HabitatType)) / n(),
    missing_depth = 100 * sum(is.na(DepthRange)) / n(),
    missing_swept_area = 100 * sum(is.na(SweptArea)) / n(),
    
    # Suspicious values
    zero_fishing_hours = 100 * sum(fishing_hours == 0, na.rm = TRUE) / sum(!is.na(fishing_hours)),
    large_fishing_hours = 100 * sum(fishing_hours > 24, na.rm = TRUE) / sum(!is.na(fishing_hours)),
    suspicious_gear_width = 100 * sum(avg_gearWidth > 1000 | avg_gearWidth < 0, na.rm = TRUE) / sum(!is.na(avg_gearWidth)),
    suspicious_oal = 100 * sum(avg_oal > 120 | avg_oal < 0, na.rm = TRUE) / sum(!is.na(avg_oal)),
    suspicious_kw = 100 * sum(avg_kw > 5000 | avg_kw < 0, na.rm = TRUE) / sum(!is.na(avg_kw)),
    
    .groups = "drop"
  )

# Calculate an overall anomaly score (0-100, higher means more potential issues)
anomaly_metrics <- anomaly_metrics %>%
  rowwise() %>%
  mutate(
    missing_data_score = mean(c(missing_fishing_speed, missing_gear_width, missing_kw, 
                              missing_oal, missing_habitat, missing_depth, missing_swept_area), 
                           na.rm = TRUE),
    suspicious_value_score = mean(c(zero_fishing_hours, large_fishing_hours, 
                                 suspicious_gear_width, suspicious_oal, suspicious_kw), 
                               na.rm = TRUE),
    overall_anomaly_score = (missing_data_score * 0.7 + suspicious_value_score * 0.3)
  ) %>%
  ungroup() %>%
  arrange(desc(overall_anomaly_score))

ggplot(anomaly_metrics, aes(x = year, y = overall_anomaly_score, color = country, group = country)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "Overall Data Anomaly Score by Country and Year",
       subtitle = "Higher score indicates more potential data quality issues",
       x = "Year", y = "Anomaly Score (0-100)") +
  scale_x_continuous(breaks = seq(min(anomaly_metrics$year), max(anomaly_metrics$year), by = 1))

datatable(anomaly_metrics)
```


## Summary of Analysis

```{r summary_table}
# Create a summary table for swept area calculation quality assessment with special handling for seine gears
sa_quality_summary <- data %>%
  # First create a flag for seine gears and identify placeholder values
  mutate(
    is_seine = gear_code %in% c("SDN", "SSC"),
    is_placeholder_width = avg_gearWidth %in% c(999, 9999, 99999, 999999) | 
      avg_gearWidth < 0
  ) %>%
  # Group by country first to get proper statistics
  group_by(country) %>%
  summarise(
    # Basic record counts
    total_records = n(),
    seine_records = sum(is_seine, na.rm = TRUE),
    other_records = total_records - seine_records,
    has_seine = seine_records > 0,
    
    # Placeholder detection
    placeholder_count = sum(is_placeholder_width, na.rm = TRUE),
    placeholder_pct = round(100 * placeholder_count / sum(!is.na(avg_gearWidth)), 1),
    has_placeholders = placeholder_pct > 10, # Flag if >10% are placeholders
    
    # Swept Area information
    sa_provided_count = sum(!is.na(SweptArea)),
    sa_provided_pct = round(100 * sa_provided_count / total_records, 1),
    sa_provided = ifelse(sa_provided_pct > 5, "Yes", "No"),
    
    # Safe calculation of statistics - check if we have any data first
    has_sa_data = sum(!is.na(SweptArea)) > 0,
    min_sa = ifelse(has_sa_data, min(SweptArea, na.rm = TRUE), NA),
    max_sa = ifelse(has_sa_data, max(SweptArea, na.rm = TRUE), NA),
    median_sa = ifelse(has_sa_data, median(SweptArea, na.rm = TRUE), NA),
    q25_sa = ifelse(has_sa_data, quantile(SweptArea, 0.25, na.rm = TRUE), NA),
    q75_sa = ifelse(has_sa_data, quantile(SweptArea, 0.75, na.rm = TRUE), NA),
    
    # Gear width information - accounting for placeholders
    seine_width_provided_count = sum(!is.na(avg_gearWidth) & is_seine & !is_placeholder_width, na.rm = TRUE),
    seine_width_provided_pct = round(100 * seine_width_provided_count / max(seine_records, 1), 1),
    seine_width_provided = ifelse(seine_width_provided_pct > 5 & seine_records > 0, "Yes", "No"),
    
    other_width_provided_count = sum(!is.na(avg_gearWidth) & !is_seine & !is_placeholder_width, na.rm = TRUE),
    other_width_provided_pct = round(100 * other_width_provided_count / max(other_records, 1), 1),
    other_width_provided = ifelse(other_width_provided_pct > 5, "Yes", "No"),
    
    # Calculate width statistics for each gear type - excluding placeholders
    has_seine_width_data = sum(!is.na(avg_gearWidth) & is_seine & !is_placeholder_width, na.rm = TRUE) > 0,
    seine_max_width = ifelse(has_seine_width_data, 
                             max(avg_gearWidth[is_seine & !is_placeholder_width], na.rm = TRUE), 
                             NA),
    seine_median_width = ifelse(has_seine_width_data,
                                median(avg_gearWidth[is_seine & !is_placeholder_width], na.rm = TRUE),
                                NA),
    
    has_other_width_data = sum(!is.na(avg_gearWidth) & !is_seine & !is_placeholder_width, na.rm = TRUE) > 0,
    other_max_width = ifelse(has_other_width_data,
                             max(avg_gearWidth[!is_seine & !is_placeholder_width], na.rm = TRUE),
                             NA),
    other_median_width = ifelse(has_other_width_data,
                                median(avg_gearWidth[!is_seine & !is_placeholder_width], na.rm = TRUE),
                                NA),
    
    # Determine likely units for gear width
    seine_width_units = case_when(
      !has_seine | !has_seine_width_data ~ "No seine data",
      has_placeholders & seine_records > 0 ~ "Contains placeholders",
      seine_max_width > 5000 ~ "Likely meters (6-12km range)",
      seine_max_width > 0 & seine_max_width < 20 ~ "Likely kilometers",
      TRUE ~ "Uncertain"
    ),
    
    other_width_units = case_when(
      !has_other_width_data ~ "No data",
      has_placeholders ~ "Contains placeholders",
      other_max_width > 1000 ~ "Suspicious (>1000m)",
      other_max_width > 500 ~ "Likely meters (high value)",
      other_max_width > 20 & other_max_width <= 500 ~ "Likely meters (expected trawl range)",
      other_max_width > 1 & other_max_width <= 20 ~ "Uncertain - check methodology",
      other_max_width > 0.02 & other_max_width <= 1 ~ "Likely kilometers",
      other_max_width > 0 & other_max_width <= 0.02 ~ "Suspicious (too small)",
      TRUE ~ "Uncertain"
    ),
    
    # Vessel characteristics
    oal_provided_count = sum(!is.na(avg_oal)),
    oal_provided_pct = round(100 * oal_provided_count / total_records, 1),
    oal_provided = ifelse(oal_provided_pct > 50, "Yes", "No"),
    
    kw_provided_count = sum(!is.na(avg_kw)),
    kw_provided_pct = round(100 * kw_provided_count / total_records, 1),
    kw_provided = ifelse(kw_provided_pct > 50, "Yes", "No"),
    
    # Fishing hours information
    hours_provided_count = sum(!is.na(fishing_hours)),
    hours_provided_pct = round(100 * hours_provided_count / total_records, 1),
    hours_provided = ifelse(hours_provided_pct > 50, "Yes", "No"),
    
    has_hours_data = sum(!is.na(fishing_hours)) > 0,
    median_hours = ifelse(has_hours_data, median(fishing_hours, na.rm = TRUE), NA),
    likely_valid_hours = case_when(
      !has_hours_data ~ "No data",
      median_hours > 0 & median_hours < 24 ~ "Yes",
      TRUE ~ "Suspicious"
    ),
    
    # Fishing speed information
    speed_provided_count = sum(!is.na(avg_fishing_speed)),
    speed_provided_pct = round(100 * speed_provided_count / total_records, 1),
    speed_provided = ifelse(speed_provided_pct > 50, "Yes", "No"),
    
    has_speed_data = sum(!is.na(avg_fishing_speed)) > 0,
    median_speed = ifelse(has_speed_data, median(avg_fishing_speed, na.rm = TRUE), NA),
    likely_valid_speed = case_when(
      !has_speed_data ~ "No data",
      median_speed > 0 & median_speed < 15 ~ "Yes",
      TRUE ~ "Suspicious"
    )
  ) %>%
  # Add magnitude-based assessment for swept area
  mutate(
    # Determine magnitude range of swept area values based on maximum value if no valid median
    sa_magnitude = case_when(
      !has_sa_data ~ "No data",
      is.na(median_sa) ~ "No data",
      median_sa > 1000000 ~ "Very high (>10^6)",
      median_sa > 10000 ~ "High (10^4-10^6)",
      median_sa > 100 ~ "Medium (10^2-10^4)",
      median_sa > 0 ~ "Low (<10^2)",
      TRUE ~ "Zero values"
    ),
    
    # Refined unit determination based on magnitude 
    likely_sa_units = case_when(
      !has_sa_data ~ "No data",
      is.na(median_sa) ~ "No data",
      median_sa > 1000000 ~ "Almost certainly sq. meters",
      median_sa > 10000 & median_sa <= 1000000 ~ "Likely sq. meters",
      median_sa < 100 ~ "Likely sq. kilometers",
      median_sa >= 100 & median_sa <= 10000 ~ "Uncertain - check methodology",
      TRUE ~ "Contains zeros or placeholders"
    ),
    
    # Specific conversion recommendation
    sa_conversion_needed = case_when(
      !has_sa_data ~ "No data to convert",
      likely_sa_units == "Almost certainly sq. meters" ~ "Divide by 1,000,000",
      likely_sa_units == "Likely sq. meters" ~ "Likely divide by 1,000,000",
      likely_sa_units == "Likely sq. kilometers" ~ "Keep as is",
      TRUE ~ "Manual review needed"
    ),
    
    # Add overall assessment
    can_calculate_missing_sa = case_when(
      sa_provided == "Yes" ~ "NA - already provided",
      (seine_width_provided == "Yes" | other_width_provided == "Yes") & 
        hours_provided == "Yes" & speed_provided == "Yes" ~ "Yes - direct calculation",
      (seine_width_provided == "No" | other_width_provided == "No") & 
        (oal_provided == "Yes" | kw_provided == "Yes") & 
        hours_provided == "Yes" & speed_provided == "Yes" ~ "Yes - need to estimate gear width",
      TRUE ~ "No - insufficient data"
    )
  ) %>%
  arrange(desc(sa_provided_pct))

# Create a more informative table focusing on swept area units
sa_decision_table <- sa_quality_summary %>%
  select(
    country,
    sa_provided,
    median_sa,
    min_sa,
    max_sa,
    sa_magnitude,
    likely_sa_units,
    sa_conversion_needed,
    has_seine,
    seine_width_provided,
    seine_width_units,
    has_placeholders,
    placeholder_pct,
    other_width_provided,
    other_width_units,
    oal_provided,
    kw_provided,
    hours_provided,
    likely_valid_hours,
    speed_provided,
    likely_valid_speed,
    can_calculate_missing_sa
  )

# Create a formatted version of the table with better numeric display
sa_decision_table_formatted <- sa_decision_table %>%
  mutate(
    median_sa = case_when(
      is.na(median_sa) ~ "No data",
      TRUE ~ formatC(median_sa, format = "e", digits = 2)
    ),
    min_sa = case_when(
      is.na(min_sa) ~ "No data",
      TRUE ~ formatC(min_sa, format = "e", digits = 2)
    ),
    max_sa = case_when(
      is.na(max_sa) ~ "No data",
      TRUE ~ formatC(max_sa, format = "e", digits = 2)
    )
  )

# Display the table with appropriate caption
datatable(sa_decision_table_formatted, 
          caption = "Assessment of Swept Area Data Quality and Standardization Needs by Country",
          options = list(pageLength = 15)) %>%
  formatStyle(
    "sa_magnitude",  # Double quotes instead of single quotes
    backgroundColor = styleEqual(
      c("Very high (>10^6)", "High (10^4-10^6)", "Medium (10^2-10^4)", "Low (<10^2)", "No data"),
      c('#ffcccc', '#ffffcc', '#ccffcc', '#ccccff', '#eeeeee')
)
) %>%
  formatStyle(
    "sa_conversion_needed",  # Double quotes instead of single quotes
    backgroundColor = styleEqual(
      c("Divide by 1,000,000", "Likely divide by 1,000,000", "Keep as is", "Manual review needed", "No data to convert"),
      c('#ffcccc', '#ffffcc', '#ccffcc', '#ffffcc', '#eeeeee')
    )
  ) %>%
  formatStyle(
    "has_placeholders",  # Double quotes instead of single quotes
    backgroundColor = styleEqual(
      c(TRUE, FALSE),
      c('#ffcccc', '#ffffff')
    )
  )
```

## 15. Known Issues and Recommendations

### Known Issues

1. **Portugal** has not submitted data since 2018.
2. **Norway** has not submitted data since 2022.
3. **Spain** only submitted data for 2023 in the most recent submission.
4. Mesh size information is largely missing or NULL. (Can be derived from metier?)
5. ICES average fishing speed appears to be mostly missing.
6. Gear width values are inconsistent across countries (meters vs. kilometers).
7. Average interval values appear to be reported in different units (minutes vs. hours).
8. Swept area values show inconsistency in units (square meters vs. square kilometers).


## 16. Session Information

```{r session_info}
# Print session information for reproducibility
sessionInfo()
```